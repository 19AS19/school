# **History of Computing**
## Terminology

- **Specific/special purpose machines** are machines that have a limited set of instructions which cannot be changed, for example, a desk calculator.

- **General purpose machines** are machines that can carry out a wide range of tasks and are not limited to a specific purpose.

- **Programmable computers** can be re-programmed to improve previous programs or to solve completely different problems.

    - In addition to being programmable and general purpose, modern computers are also digital and electronic.

    - They are digital because they use discreet values for their calculations. Analog or continuous signals can have an infinite number of values in a given range. Digital signals take on a limited number of values.

    - Modern digital computers use 1 or 0, these  are binary digital computers. However, in theory, you could build a computer with any number of discreet digits, for example, base 10.

    - Electronic computers operate using electricity. They use DC as it is easier to produce using batteries. it has a constant voltage that is either on or off. This is ideal for modern electronics which are built around transistors and act as switches with on or off states. There allow us to model boolean algebra useing electronics.

- **Conductors:** Materials that allow electricity to flow freely through them, *e.g. copper*

- **Insulators:** Materials that dont allow eletricity to flow freely through them, *e.g. glass*

- **Semiconductors:** Designed so they can act as a conductor or insulator or both. This special property allows them to control the flow of electricity making modern computers possible.

- **Vacuum Tubes:** Electrical devices that control the flow of electricity. They were used in the first computers until they were replaced by transistors.

- **Transistors:** Silicon, under certain conditions they can act as a conductor or insulator, it is a semi-conductor. By adding impurities, in a process called doping, scientists can control the flow of electrons and so make an electronic switch.


## Generations of Computers
1. **1st Generation Computers:** Vacuum Tubes
2. **2nd Generation Computers:** Transistors
3. **3rd Generation Computers:** Integrated Circuits
4. **4th Generation Computers:** Micro-Processors

## Early Counting Devices
- **Pile of Stones:** Adding or removing stones from a pile would provide a way of calculating and storing the result

- **Abacus:** A frame with wires on it. Beads were treaded onto the wires which could side back and forth to calculate values. Abacus' are still used today but are not computers because they only act as an aid to the person doing the computation.

## First Computers
The original meaning of the term computer was a person who performed mathematical calculations. For example:
- Calculating the position of stars and movement of the planets
- Compiling mathematics tables and trajectories of missiles

## Early Computing Machines
### 1600s
- **Slide rule:** a mechanical engine, a mechanical calculator that could solve polynomial equations.
- It was a *special purpose machine*

### 1800s
- 1822
    - **Charles Babbage difference engine**, a mechanical calculator that could solve polynomial equations
    - It was a *special purpose machine* 

- 1830
    - **Charles Babbage** designs the **Analytical Engine**.
    - Designed for general purpose computations, with data stored on **punch cards**(thich paper with holes punched in them). The computations were specified by programs also stored on the punch cards. Though never completed, the design included mechanical memory and the equivalent of a CPU. 
    - Programable and general purpose it was arguably the World's first non-human computer.
    - It had the four key features of all modern computers: Input, Storage, Processing and Output.

- 1815-1852
    - **Ada Lovelace:** first computer programmer.
    - Took a interese in the *Analytical Engine*., she designed and published the fisrt algorythm designed to be executed by a machine. She in considered the *first computer programmer*.
    - While many other mechanical computers were devised they were all very complex, large and heavy. This made them expensive and difficult to produce in large quantities.

## 1900s
- 1936
    - **Alan Turing**, described a mathematical model of computation called the a-machine (automatic machine) which later on became known as the *Turing Machine*. A Turing Machine can be constructed to solve any given computer algorythm. It is in this sense, the first concept of a universal, all-purpose, computing machine. This laid the foundation for AI and machine learning.

- 1940
    - *Alan Turing* developed the Bombe machine to break the encryption of the enigma machine. Both machines were specific purpose.

- 1943
    - **Colossus:** World's first programmable electronic digital computer.
        - Created 1943, Bletchley park UK to break codes during WW2.
        - Could not store programs in memory, just data
        - Had to be rebuilt using cables and switches every time a new program was needed. Not considered General Purpose as it was solely used for code breaking.

    - **ENIAC (Electronic Numerical Integrator and Computer)**
        - American programmable computer. Considered the first general purpose digital computer.
        - Similar to **Colossus**, had to be rebuilt for each program.
        - *Kay McNuity* was one of the first programmers of the **ENIAC**.
        - *Berry Jean Jennings* and *Fran Bilas* were also women programmers of the **ENIAC**.

    - Both the Colossus and ENIAC used punch-cards and vacuum tubes and did not store the programs in memory.
    - The Colossus was a binary computer but the ENIAC was a decimal computer.

- 1947
    - The digital revolution began with the invention of the solid state transistor at Bell Labs USA. The device which can act like a switch, turning tiny electric cuttents on or off, and also as an amplifier of electric current.

    - Logic gates which allow us to build circuits for Boolean Algebra are made primarily of transistiors, as are memory components and CPU's.

- 1953
    - Invention of high-level programming languages.
    - In the early days of computing, electronic computers could only be programmed by numbers, tape, punch cards, or even manually manipulating the thermonic valves(vacuum tube) to certain settings.
    - After WW2, *Grace Hopper* worked on the first commercial computer called the **UNIVAC**(Universal Automatic Computer). A stored program computer, it used magnetic tape instead of punch-cards. It was a decimal computer that used vacuum tubes.
    - In 1953 she invented the first high level programming language, **A-0**, that used words and expressions to program the **UNIVAC**. She also created the first modern day compiler and coined the phrase **BUG**. **A-0** evolved into **Flow-Matic** and eventually became the widely used **COBOL**

- 1954
    - The first computer without vacuum tubes. Known as **TRADIC** (**Tra**nsistorized **D**igital **C**omputer )
    - IBM invented the **FORTRAN** programming language

- 1956
    - MIT was working on the keyboard input and output

- 1957
    - The soviet union launched Sputnik, the first unmanned satellite in space.

- 1958
    - Integrated circuits were invented
    - Integrated circuits (**IC**) were invented in 1958, independently, by electrical engineers *Jack Kilby* (Texas Instruments) and *Robert Noyce* (Fairchild Semiconductor).
    - They consist of a number of electronic circuits on a single chip
    - The motivation was 'How can we squeeze more components into a smaller space, at reduced cost and operating at faster speeds?'

- 1964
    - **BASIC** programming language was invented.

- 1973
    - The Ethernet was developed at *Xeron Labs*. It was a system for connecting computers withing a building using hardware running from machine to machine.
    - *Martin Cooper*, a Motorola researcher, made the first ever call on a mobile phone.
    - **ARPA**'s Transmission Protocol / Internet Protocol (TCP / IP) was invented by *Vint Cerf* and *Bob Kahn*
    - In 1977 **ARPA** demonstrated that it could connect several different networks. This became known as the internet
    - **NOTE** - **ARPA** was the precursor to **DARPA** (Defence)
    - The first **Apple** was completed in 1976 - users had to build their own case for it and software had to be custom written for the hardware.
    - The second **Apple** was completed in 1977, Inspired by modern electronic commodities such as *TV* and *Stereos*, the modern *PC* had truly arrived.

- 1989
    - The **World Wide Web (WWW)** was invented by *Tim Berners-Lee* while working at the **CERN** laboratories in *Switzerland*.
    - The internet is a global network that connects computers and computer networks. The linking of computer networks is called **Internetworking**, from which we get the name *internet*

- 2000 - 2020 (Modern Day)
    - **Cloud Computing** and the **smartphone**
    - Mainframe computers have existed since modern computing evolved, where end users hook up their terminal to a larger system with greater speed and processing power
    - Limited Bandwidth and connectivity meant companies could not provide cloud computing on a commercial scale. That all changed in the 1900's as the internet bandwidth developed. One of the first companies to capitalise was **Amazon**. Their **Amazon Web Service (AWS)**, grew out of the realisation that their data centres had more computing power than the company could use. So they began to rent their computers as virtual servers to clients who wanted to avail of online storage and computing power.
    - Cloud Computing allowed for virtualisation - the simulation of a device or a resource. It creates an environment for a user that is independent of physical infrastructure. For example, *Office 365* of *Photoshop* online are software programs that run on the cloud

    - **Web 2.0**

    - The original internet developed in 1989 had very static html pages where users could view or download content - it was **Web 1.0**. As the internet developed, in the mid-2000s **Web 2.0** was coined to capture the change to a dynamic **World Wide Web**

    -   Javascript, for example, was developed in 1995 to give the browser to giev the browser more choice and responsiveness. By the early 2000s, JS could do more and more throughwebv browers. As the web became more and more of a business and social tool, technologies such as AJAX (Asyncronous Javascript and eXtenstible markup language) allowed pages to update seamlessly without the need for http requests. Google Maps uses an AJAX engine to allow users work on data in real time in their browsers.


# Moores Law

|Processor|Transistor Count|Year|Process|Compparable Objects|Electromagnetic Spectrum|
|---|---|---|---|---|---|
|Intel 4004|2300|1971|10nm|Red Blood Cells|Infra Red|
|Motorola 68000|68000|1979|4nm|Most Bacteria|Infra Red|
|Intel 80486|1.18 Million|1989|1nm|E-coli|Visible Light 0.4 - 0.7 um|
|Pentium III|9.5 Million|1999|250nm|Pollen, Viruses|Approaching UV light|
|Six Core i7/8|2 Billion+|2011|32nm|Molecules|UV light|
|Exynos 8895|20 Billion+|2017|10nm|50 Atoms of silicon||


- 2021 - present

    - Web 3.0

    - Building on web 2.0, web 3.0 places a strong emphasis on decentralized applications and will probablyu make extensive use of blockchain-basedc technologies. It will also use machinbe learning and AI to empower a more intelligent and adaptive web.

- November 2022

    - Release of ChatGPT


<br><br>

- **1939**: The turing machine
- **1942-1946**: First Electronic Computers: Colossus and ENIAC
- **1947**: Solid State Transistors
- **1953**: Invention of High Level Programming Languages
- **1958**: Integrated Circuits
- **1973**: Mobile Phones and Ingterconnected Computers
- **1977**: First Modern PC - Apple II
- **1989**: The World Wide Web
- **2000-2020**: Cloud Computing and the Smart Phone